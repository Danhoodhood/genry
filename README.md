### Отчет 2: Разработка датасета с точки зрения Machine Learning Engineer

#### Введение
В этом отчете я хочу поделиться процессом работы с датасетом test_data.txt с точки зрения Machine Learning Engineer. Моя задача заключалась в подготовке датасета для использования в моделях машинного обучения, особенно для задач, связанных с обработкой текстов, таких как анализ чувств, классификация фильмов и построение рекомендательных систем. Датасет должен был быть структурирован таким образом, чтобы его можно было эффективно использовать в алгоритмах анализа и классификации.

#### Задачи и цели

Главной целью моей работы было подготовить датасет, который позволит обучить модели машинного обучения, а также использовать его для предсказания жанров фильмов, анализа текстов и рекомендаций. Датасет должен был быть удобен для обработки алгоритмами обработки естественного языка (NLP), а также содержать достаточно информации для создания предсказательных моделей.

#### Этапы разработки

1. Подготовка и анализ данных:
Датасет был изначально представлен в виде текстовых файлов, где каждый фильм был представлен идентификатором, названием и описанием. Я проанализировал структуру данных, убедился, что они содержат необходимые атрибуты (например, название и описание), и что текстовое описание является достаточно информативным для применения NLP-техник.

2. Предобработка текста:
На этом этапе моя работа заключалась в подготовке текстов для дальнейшего использования в моделях. Для этого я использовал несколько методов:
- Удаление стоп-слов: Это слова, которые не несут смысла для анализа (например, "и", "в", "на").
- Лемматизация: Приведение слов к их базовой форме, что помогло уменьшить количество уникальных токенов.
- Токенизация: Разбиение текста на отдельные слова или фразы для более детального анализа.

3. Преобразование текста в числовые данные:
Для использования текста в моделях машинного обучения, нужно было преобразовать его в числовые данные. Для этого я применил несколько подходов:
- TF-IDF (Term Frequency-Inverse Document Frequency): Это метод, который помогает выделить ключевые слова в тексте, учитывая частоту их появления в документе и общее количество документов в датасете.
- Word2Vec или другие эмбеддинги: Этот метод позволяет преобразовать слова в векторное представление, что позволяет захватывать их смысл.

4. Интеграция данных в модель машинного обучения:
Когда данные были подготовлены, я использовал их для обучения моделей машинного обучения. Основная задача заключалась в создании модели, которая могла бы классифицировать фильмы по жанрам или предсказать предпочтения пользователя. Для этого использовались такие алгоритмы, как:
- Классификация текста с использованием методов, таких как Naive Bayes, SVM и нейронные сети.
- Рекомендательные системы с использованием методов коллаборативной фильтрации или Content-Based Filtering.

5. Оценка качества модели:
После того как модель была обучена, я провел ее оценку с помощью таких метрик, как точность (accuracy), полнота (recall), F-мера и другие показатели, которые позволили определить, насколько хорошо модель предсказывает жанры фильмов или рекомендации.

#### Технические инструменты

Для обработки данных я использовал следующие библиотеки и инструменты:
- scikit-learn – для реализации алгоритмов классификации и предобработки данных.
- NLTK и spaCy – для обработки естественного языка, лемматизации и токенизации.
- TensorFlow или PyTorch – для более сложных моделей машинного обучения, таких как нейронные сети.
- Gensim – для работы с Word2Vec и другими методами векторизации текста.

#### Заключение
Моя работа как Machine Learning Engineer заключалась в подготовке и преобразовании текстовых данных для использования в моделях машинного обучения. Датасет был тщательно обработан, что обеспечило качественное представление информации и позволило применить различные методы машинного обучения для решения задач, таких как классификация жанров 
